{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from board_labeler import getFiles\n",
    "\n",
    "filesDir = \"labeledConstSize/\"\n",
    "\n",
    "paths = getFiles(filesDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3224 3224\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "stringLen = len(filesDir)\n",
    "m = re.compile(r\"([a-zA-Z]+(_[a-zA-Z]+)?)_\")\n",
    "\n",
    "\n",
    "\n",
    "X = [cv2.imread(x) for x in paths]\n",
    "y = [m.findall(x)[0][0] for x in paths]\n",
    "\n",
    "dictClasses = {\n",
    "    \"empty\":0,\n",
    "    \"bishop_black\":1,\n",
    "    \"bishop_white\":2,\n",
    "    \"king_black\":4,\n",
    "    \"king_white\":5,\n",
    "    \"knight_black\":6,\n",
    "    \"knight_white\":7,\n",
    "    \"pawn_black\":8,\n",
    "    \"pawn_white\":9,\n",
    "    \"queen_black\":10,\n",
    "    \"queen_white\":11,\n",
    "    \"rook_black\":12,\n",
    "    \"rook_white\":13,\n",
    "}\n",
    "y = [[dictClasses[x]] for x in y]\n",
    "\n",
    "# temp1 = [x.shape for x in X]\n",
    "# temp = set(temp1)\n",
    "\n",
    "# temp3 = [temp1.count(x) for x in temp]\n",
    "# print(temp)\n",
    "# print(temp3)\n",
    "\n",
    "print(f\"{len(X)} {len(y)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0]\n",
      " [ 0]\n",
      " [ 2]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 8]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 8]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 9]\n",
      " [ 6]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 9]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 8]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [13]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 9]\n",
      " [ 8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.asanyarray(X)\n",
    "y = np.asanyarray(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(y_train[0:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "68/68 [==============================] - 1s 4ms/step - loss: 427.7690 - accuracy: 0.6162\n",
      "Epoch 2/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 44.9883 - accuracy: 0.8315\n",
      "Epoch 3/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 4.9271 - accuracy: 0.9056\n",
      "Epoch 4/20\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 16.2825 - accuracy: 0.8551\n",
      "Epoch 5/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 11.7868 - accuracy: 0.9014\n",
      "Epoch 6/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 2.2706 - accuracy: 0.9519\n",
      "Epoch 7/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.4995 - accuracy: 0.9532\n",
      "Epoch 8/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.9727\n",
      "Epoch 9/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.9815\n",
      "Epoch 10/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.9810\n",
      "Epoch 11/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 12.3408 - accuracy: 0.8843\n",
      "Epoch 12/20\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 28.8414 - accuracy: 0.8370\n",
      "Epoch 13/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 1.8684 - accuracy: 0.9528\n",
      "Epoch 14/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.9731\n",
      "Epoch 15/20\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.9755\n",
      "Epoch 16/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.9718\n",
      "Epoch 17/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.8872 - accuracy: 0.9620\n",
      "Epoch 18/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.9745\n",
      "Epoch 19/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.9838\n",
      "Epoch 20/20\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.1690 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d26e2c5e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(500, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(250, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(100, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(14, activation = tf.nn.softmax)])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(X_train,y_train,epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.23837880790233612\n",
      "Test accuracy: 0.9802631735801697\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose = 0) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/firstmodel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/firstmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from board_finder import getBoardCoords,imageResize\n",
    "\n",
    "img = cv2.imread(paths[0])\n",
    "\n",
    "predictionClass = model.predict(X_test)\n",
    "\n",
    "dct = {v: k for k, v in dictClasses.items()}\n",
    "\n",
    "cv2.imshow(dct[predictionClass[8].argmax()],X_test[8])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a65bfb053b84dfe41b67f1cec0c790434c65b552b531ac67bdc76b65fabe208"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
